{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1832a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def scrapper():\n",
    "    url = 'https://www.linkedin.com/jobs/search/?currentJobId=3473931372&f_TPR=r2592000&geoId=106057199&keywords=Desenvolvimento%20De%20Software&location=Brasil&originalSubdomain=br'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}\n",
    "    r = requests.get(url, headers)\n",
    "    soup = BeautifulSoup(r.content, 'lxml')\n",
    "    return soup\n",
    "\n",
    "\n",
    "def extract(soup):\n",
    "    jobs = soup.find_all(\n",
    "        'div', class_=\"base-card relative w-full hover:no-underline focus:no-underline base-card--link base-search-card base-search-card--link job-search-card\")\n",
    "    for item in jobs:\n",
    "        title = item.find('a').text.strip()\n",
    "        company = item.find('h4').text.strip()\n",
    "        location = item.find(\n",
    "            'span', class_='job-search-card__location').text.strip()\n",
    "        job = {\n",
    "            'Title': title,\n",
    "            'Company': company,\n",
    "            'location': location\n",
    "        }\n",
    "        joblist.append(job)\n",
    "    return\n",
    "\n",
    "\n",
    "joblist = []\n",
    "#page = int(input(f'enter the page number you are looking:'))\n",
    "\n",
    "for i in range(0,40):\n",
    "    print(f'gettinf page,{i}')\n",
    "\n",
    "    s = scrapper()\n",
    "    c = extract(s)\n",
    "\n",
    "df = pd.DataFrame(joblist)\n",
    "df.to_csv('teste433.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff6fee27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting page 1...\n",
      "Getting page 2...\n",
      "Getting page 3...\n",
      "Getting page 4...\n",
      "Getting page 5...\n"
     ]
    }
   ],
   "source": [
    "def scrapper(page_number):\n",
    "    url = f'https://www.linkedin.com/jobs/search/?currentJobId=3462241207&distance=25&geoId=106057199&keywords=data%20scientist&position=1&pageNum={page_number}'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}\n",
    "    r = requests.get(url, headers)\n",
    "    soup = BeautifulSoup(r.content, 'lxml')\n",
    "    return soup\n",
    "\n",
    "joblist = []\n",
    "total_pages = 5  # número de páginas que deseja extrair\n",
    "\n",
    "for i in range(total_pages):\n",
    "    print(f'Getting page {i + 1}...')\n",
    "    s = scrapper(i + 1)  # passar o número da página\n",
    "    c = extract(s)\n",
    "\n",
    "df = pd.DataFrame(joblist)\n",
    "df.to_csv('jobsds.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
